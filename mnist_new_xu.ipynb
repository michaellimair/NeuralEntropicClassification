{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if(torch.cuda.is_available()) else \"cpu\")\n",
    "print(device)\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size': 128, #size of the batches\n",
    "    'image_size': 32, #size of each image dimension\n",
    "    'lr': 0.0001, #adam: learning rate\n",
    "    'b1': 0.5, #adam: decay of first order momentum of gradient\n",
    "    'b2': 0.999, #adam: decay of first order momentum of gradient\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "#     transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize(params['image_size']),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Lambda(lambda x: x.repeat(3,1,1)),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST(root='./data', train='train',\n",
    "                       download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=params['batch_size'], pin_memory=True,\n",
    "                                          shuffle=True)\n",
    "testset = datasets.MNIST(root='./data', train=False,\n",
    "                      download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=params['batch_size'], pin_memory=True,\n",
    "                                         shuffle=False)\n",
    "\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss fucntion of MINEE classification\n",
    "# loss = E(f(x*,x,y)) - E[ln(1/|y|) * sum_y(e^f(x*,x,y))]\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "class_vectors = [] * 10\n",
    "for i in range(len(classes)):\n",
    "    # I think it is better to use numpy array instead, as GPU will easily run out of memory\n",
    "    # And PyTorch concatenation takes up a huge amount of memory\n",
    "    class_vectors.append(FloatTensor())\n",
    "\n",
    "def loss_func(x_output, y):\n",
    "    mean_f = x_output.mean()    #  E(f(x*,x,y))\n",
    "    for idx, label in enumerate(y):\n",
    "        class_vectors[label.item()] = torch.cat((class_vectors[label.item()], x_output[idx]), 0)\n",
    "    class_sum = []\n",
    "    for vect in class_vectors:\n",
    "        class_sum.append(vect.exp().sum(dim=-1))\n",
    "    class_sum = FloatTensor(class_sum)\n",
    "    \n",
    "    mean_class = log(1/len(classes))*class_sum.mean()\n",
    "    loss = mean_f - mean_class\n",
    "    print(loss)\n",
    "    del class_sum\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    \"\"\"\n",
    "    Initialise weights of the model.\n",
    "    \"\"\"\n",
    "    if(type(m) == nn.ConvTranspose2d or type(m) == nn.Conv2d):\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif(type(m) == nn.BatchNorm2d):\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Architecture based on InfoGAN paper implementation on Natsu6767/InfoGAN-PyTorch repo\n",
    "#  Problematic for now, so reverting to basic architecture\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         # 1 input image channel, 64 output channels, 4x4 square convolution kernel\n",
    "#         self.conv1 = nn.Conv2d(1, 64, 4, 2, 1)\n",
    "\n",
    "#         self.conv2 = nn.Conv2d(64, 128, 4, 2, 1, bias=False)\n",
    "#         self.bn2 = nn.BatchNorm2d(128)\n",
    "\n",
    "#         self.conv3 = nn.Conv2d(128, 1024, 7, bias=False)\n",
    "#         self.bn3 = nn.BatchNorm2d(1024)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.leaky_relu(self.conv1(x), 0.1, inplace=True)\n",
    "#         x = F.leaky_relu(self.bn2(self.conv2(x)), 0.1, inplace=True)\n",
    "#         x = F.leaky_relu(self.bn3(self.conv3(x)), 0.1, inplace=True)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic architecture implemented in the PyTorch tutorial\n",
    "# https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=[3,3], padding=1, stride=1)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=[3,3], padding=1, stride=1)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 8 * 8, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.max_pooling = nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = self.max_pooling(F.relu(self.conv1(x)))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = self.max_pooling(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().cuda() if torch.cuda.is_available() else Net()\n",
    "net.apply(weights_init)\n",
    "print(\"Neural Network is successfully defined in device %s.\" % device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=params['lr'], betas=(params['b1'], params['b2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "#         print(\"inputs shape\", inputs.shape)\n",
    "#         print(\"label shape\", labels.shape)\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs).cuda()\n",
    "#         print(outputs.size())\n",
    "#         loss = criterion(outputs, labels)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward(retain_graph=True) # HIGH Memory Usage\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 200 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "net = Net()    \n",
    "train_data = torch.randn(1, 1, 32, 32)\n",
    "output = net(train_data)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "target2 = target.view(1, -1)  # make it the same shape as output\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "# loss = criterion(output, target)\n",
    "print(output)\n",
    "print(target)\n",
    "print(target2)\n",
    "\"\"\"\n",
    "print(\"Commented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(20,10).cuda()\n",
    "print(a.mean())\n",
    "print(torch.sum(a,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.to(device)\n",
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += torch.sum(predicted.to(device) == labels.to(device)).item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted.to(device) == labels.to(device)).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
